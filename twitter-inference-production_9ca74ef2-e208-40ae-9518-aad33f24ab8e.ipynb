{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Our Twitter Inference Towards Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://assets.bwbx.io/images/users/iqjWHBFdfxIU/inIpLScj8Lco/v1/-1x-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the probability that a tweet originating from within Colombia contains at least 1 occurence of the word \"yo\" with any given composition of accents, and capital and lowercase letters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tweepy\n",
    "from tweepy import Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = os.getenv('TWITTER_CONSUMER_KEY')\n",
    "CONSUMER_SECRET = os.getenv('TWITTER_CONSUMER_SECRET')\n",
    "ACCESS_TOKEN = os.getenv('TWITTER_ACCESS_TOKEN')\n",
    "ACCESS_TOKEN_SECRET = os.getenv('TWITTER_ACCESS_TOKEN_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COLOMBIA_GEO_LOCATION_BOUNDING_BOX = [-78.31, 0.44, -70.71, 11.39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define some cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def make_lowercase(tweet):\n",
    "    return tweet.lower()\n",
    "\n",
    "\n",
    "def remove_diacritics(tweet):\n",
    "    return unidecode(tweet)\n",
    "\n",
    "\n",
    "def remove_non_alpha_characters(tweet):\n",
    "    return ''.join(character for character in tweet if character.isalpha() or character == ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a stream listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATABASE_NAME = 'twitter_inference'\n",
    "TABLE_NAME = 'tweets'\n",
    "USER = 'willwolf'\n",
    "HOST = 'localhost'\n",
    "PASSWORD = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from tweepy import StreamListener\n",
    "\n",
    "\n",
    "class PersistedStreamListener(StreamListener):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._database_connection = psycopg2.connect(dbname=DATABASE_NAME, user=USER, host=HOST, password=PASSWORD)\n",
    "        super().__init__()\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        cleaned_status_text = self._clean_status_text(status.text)\n",
    "        self._insert_status(id_str=status.id_str, text=cleaned_status_text)\n",
    "        \n",
    "    def _clean_status_text(self, status_text):\n",
    "        cleaned_status_text = status_text\n",
    "        for cleaning_function in self._cleaning_functions:\n",
    "            cleaned_status_text = cleaning_function(cleaned_status_text)\n",
    "        return cleaned_status_text\n",
    "    \n",
    "    def _insert_status(self, id_str, text):\n",
    "        cursor = self._database_connection.cursor()\n",
    "        insert_statement = \"\"\"INSERT INTO {table_name} VALUES ('{id_str}', '{text}')\"\"\".format(\n",
    "                table_name=TABLE_NAME, id_str=id_str, text=text)\n",
    "\n",
    "        cursor.execute(insert_statement)\n",
    "        self._database_connection.commit()\n",
    "        \n",
    "        cursor.close()\n",
    "        \n",
    "    @property\n",
    "    def _cleaning_functions(self):\n",
    "        return [make_lowercase, remove_diacritics, remove_non_alpha_characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "streaming_api = Stream(auth=auth, listener=PersistedStreamListener())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.imgur.com/mj059cS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "streaming_api.filter(locations=COLOMBIA_GEO_LOCATION_BOUNDING_BOX, async=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta as beta_distribution\n",
    "\n",
    "\n",
    "X_VALUES = np.linspace(0, 1, 1002)[1:-1]\n",
    "DATABASE_CONNECTION = psycopg2.connect(dbname=DATABASE_NAME, user=USER, host=HOST, password=PASSWORD)\n",
    "KEYWORD = 'yo'\n",
    "\n",
    "\n",
    "def fetch_tweets(database_connection=DATABASE_CONNECTION):\n",
    "    cursor = database_connection.cursor()\n",
    "    select_statement = \"\"\"SELECT text FROM {table}\"\"\".format(table=TABLE_NAME)\n",
    "    cursor.execute(select_statement)\n",
    "    result = cursor.fetchall()\n",
    "    \n",
    "    return [tweet[0] for tweet in result]\n",
    "\n",
    "\n",
    "def compute_alpha_and_beta(tweets, keyword=KEYWORD):\n",
    "    number_of_occurences = sum(keyword in tweet for tweet in tweets)\n",
    "    alpha = 1 + number_of_occurences\n",
    "    beta = 1 + (len(tweets) - number_of_occurences)\n",
    "    \n",
    "    return alpha, beta\n",
    "\n",
    "\n",
    "def compute_pdf_y_values(alpha, beta, x_values=X_VALUES):\n",
    "    return beta_distribution(alpha, beta).pdf(x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.client import push_session\n",
    "from bokeh.models import FixedTicker\n",
    "from bokeh.plotting import figure, curdoc, reset_output\n",
    "\n",
    "# reset output\n",
    "reset_output()\n",
    "\n",
    "# initialize alpha, beta\n",
    "tweets = fetch_tweets()\n",
    "alpha, beta = compute_alpha_and_beta(tweets=tweets)\n",
    "pdf_y_values = compute_pdf_y_values(alpha, beta)\n",
    "\n",
    "# create bokeh figure\n",
    "bokeh_figure = figure(\n",
    "    title='PDF of True Probability of a Tweet Containing Keyword',\n",
    "    x_axis_label='true_probability',\n",
    "    y_axis_label='probability_density',\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "bokeh_figure.xaxis[0].ticker=FixedTicker(ticks=list(np.linspace(0, 1, 21)))\n",
    "bokeh_line = bokeh_figure.line(X_VALUES, pdf_y_values, color=\"navy\", line_width=4)\n",
    "\n",
    "# open a session to keep our local document in sync with server\n",
    "session = push_session(curdoc())\n",
    "\n",
    "def update():\n",
    "    tweets = fetch_tweets()\n",
    "    alpha, beta = compute_alpha_and_beta(tweets=tweets)\n",
    "    pdf_y_values = compute_pdf_y_values(alpha, beta)\n",
    "    bokeh_line.data_source.data.update(y=pdf_y_values)\n",
    "\n",
    "curdoc().add_periodic_callback(update, 50)\n",
    "\n",
    "session.show(bokeh_figure)\n",
    "\n",
    "session.loop_until_closed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
